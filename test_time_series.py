#!/usr/bin/env python3
"""
æ™‚é–“åºåˆ—è¿½è¹¤åŠŸèƒ½å®Œæ•´æ¸¬è©¦è…³æœ¬
æ¸¬è©¦æ•¸æ“šæå–ã€åˆ†æã€è­¦å ±ç­‰æ‰€æœ‰åŠŸèƒ½
"""

import os
import sys
import json
import mysql.connector
from datetime import date, datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šè·¯å¾‘
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from rag_store.time_series_analyzer import TimeSeriesAnalyzer, process_document_for_time_series

def get_test_connection():
    """å»ºç«‹æ¸¬è©¦è³‡æ–™åº«é€£æ¥"""
    try:
        # å˜—è©¦é€£æ¥ TiDB Cloud
        tidb_host = os.getenv("TIDB_HOST")
        tidb_user = os.getenv("TIDB_USER")
        tidb_password = os.getenv("TIDB_PASSWORD")
        tidb_db = os.getenv("TIDB_DB", "rag")
        
        if all([tidb_host, tidb_user, tidb_password]):
            conn = mysql.connector.connect(
                host=tidb_host,
                user=tidb_user,
                password=tidb_password,
                database=tidb_db,
                ssl_disabled=False,
                use_unicode=True
            )
            print(f"âœ… æˆåŠŸé€£æ¥åˆ° TiDB Cloud: {tidb_host}")
            return conn
        else:
            print("âŒ TiDB Cloud ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")
            return None
            
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
        return None

def setup_test_database():
    """è¨­å®šæ¸¬è©¦è³‡æ–™åº«æ¶æ§‹"""
    print("ğŸ”§ è¨­å®šæ¸¬è©¦è³‡æ–™åº«æ¶æ§‹...")
    
    conn = get_test_connection()
    if not conn:
        print("âŒ ç„¡æ³•é€£æ¥è³‡æ–™åº«")
        return False
    
    try:
        cursor = conn.cursor()
        
        # åŸ·è¡Œæ™‚é–“åºåˆ—æ¶æ§‹ SQL
        schema_file = project_root / "scripts" / "time_series_schema.sql"
        if schema_file.exists():
            with open(schema_file, 'r', encoding='utf-8') as f:
                sql_commands = f.read()
                
            # åˆ†å‰²ä¸¦åŸ·è¡Œ SQL å‘½ä»¤
            for command in sql_commands.split(';'):
                command = command.strip()
                if command and not command.startswith('--'):
                    try:
                        cursor.execute(command)
                    except mysql.connector.Error as e:
                        if "already exists" not in str(e):
                            print(f"SQL åŸ·è¡Œè­¦å‘Š: {e}")
            
            conn.commit()
            print("âœ… è³‡æ–™åº«æ¶æ§‹è¨­å®šå®Œæˆ")
            return True
        else:
            print(f"âŒ æ‰¾ä¸åˆ°æ¶æ§‹æª”æ¡ˆ: {schema_file}")
            return False
            
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«æ¶æ§‹è¨­å®šå¤±æ•—: {e}")
        return False
    finally:
        conn.close()

def test_data_extraction():
    """æ¸¬è©¦æ•¸æ“šæå–åŠŸèƒ½"""
    print("\nğŸ“Š æ¸¬è©¦æ•¸æ“šæå–åŠŸèƒ½...")
    
    conn = get_test_connection()
    if not conn:
        return False
    
    analyzer = TimeSeriesAnalyzer(conn)
    
    # æ¸¬è©¦ç”¨æ–‡å­—ç¯„ä¾‹
    test_texts = [
        "é«”é‡: 65.5 kg, èº«é«˜: 170 cm, è¡€å£“: 120/80",
        "æ•¸å­¸æˆç¸¾: 85åˆ†, è‹±æ–‡æˆç¸¾: 78åˆ†, åœ‹æ–‡: 82åˆ†",
        "æœ¬æœˆæ”¯å‡º: NT$ 25,000å…ƒ, æ”¶å…¥: 50,000å…ƒ",
        "BMI: 22.5, é«”è„‚ç‡: 15.2%",
        "æœ¬æ¬¡å¥åº·æª¢æŸ¥çµæœï¼šé«”é‡ 68.2å…¬æ–¤ï¼Œèº«é«˜ 175å…¬åˆ†ï¼Œè¡€å£“ 125/82"
    ]
    
    success_count = 0
    for i, text in enumerate(test_texts):
        print(f"  æ¸¬è©¦æ–‡å­— {i+1}: {text[:50]}...")
        
        # æå–æ•¸æ“š
        extracted_data = analyzer.extract_numeric_values(text)
        print(f"    æå–åˆ° {len(extracted_data)} å€‹æ•¸æ“šé»")
        
        # å„²å­˜åˆ°è³‡æ–™åº«
        test_date = date.today() - timedelta(days=i)
        for data in extracted_data:
            if analyzer.store_time_series_data(
                data['type'], data['value'], test_date, 
                None, None, data['confidence']
            ):
                success_count += 1
    
    conn.close()
    print(f"âœ… æˆåŠŸæå–ä¸¦å„²å­˜ {success_count} å€‹æ•¸æ“šé»")
    return success_count > 0

def test_trend_analysis():
    """æ¸¬è©¦è¶¨å‹¢åˆ†æåŠŸèƒ½"""
    print("\nğŸ“ˆ æ¸¬è©¦è¶¨å‹¢åˆ†æåŠŸèƒ½...")
    
    conn = get_test_connection()
    if not conn:
        return False
    
    analyzer = TimeSeriesAnalyzer(conn)
    
    # æ¸¬è©¦ä¸åŒçš„æ™‚é–“åºåˆ—
    test_series = ['é«”é‡', 'æ•¸å­¸æˆç¸¾', 'æœˆæ”¯å‡º']
    
    for series_name in test_series:
        print(f"  åˆ†æ {series_name} è¶¨å‹¢...")
        
        # å–å¾—æ•¸æ“š
        data_points = analyzer.get_time_series_data(
            series_name, 
            start_date=date.today() - timedelta(days=30),
            end_date=date.today()
        )
        
        if data_points:
            print(f"    æ‰¾åˆ° {len(data_points)} å€‹æ•¸æ“šé»")
            
            # è¶¨å‹¢åˆ†æ
            trend = analyzer.analyze_trend(data_points, 30)
            print(f"    è¶¨å‹¢é¡å‹: {trend.trend_type}")
            print(f"    è®ŠåŒ–ç™¾åˆ†æ¯”: {trend.change_percentage:.1f}%")
            print(f"    ä¿¡å¿ƒåº¦: {trend.confidence:.2f}")
            
            # çµ±è¨ˆæ‘˜è¦
            stats = analyzer.get_statistics_summary(series_name, period_days=30)
            if stats:
                print(f"    æœ€æ–°å€¼: {stats.get('latest_value')}")
                print(f"    å¹³å‡å€¼: {stats.get('average_value', 0):.2f}")
        else:
            print(f"    âŒ æ²’æœ‰æ‰¾åˆ° {series_name} çš„æ•¸æ“š")
    
    conn.close()
    print("âœ… è¶¨å‹¢åˆ†ææ¸¬è©¦å®Œæˆ")
    return True

def test_alert_system():
    """æ¸¬è©¦è­¦å ±ç³»çµ±"""
    print("\nğŸš¨ æ¸¬è©¦è­¦å ±ç³»çµ±...")
    
    conn = get_test_connection()
    if not conn:
        return False
    
    analyzer = TimeSeriesAnalyzer(conn)
    
    # æª¢æŸ¥ç¾æœ‰è­¦å ±è¦å‰‡
    cursor = conn.cursor(dictionary=True)
    cursor.execute("SELECT COUNT(*) as count FROM time_series_alerts WHERE is_active = 1")
    alert_count = cursor.fetchone()['count']
    print(f"  æ‰¾åˆ° {alert_count} å€‹æ´»èºè­¦å ±è¦å‰‡")
    
    # æ¸¬è©¦è­¦å ±æª¢æŸ¥
    test_series = ['é«”é‡', 'æ•¸å­¸æˆç¸¾', 'æœˆæ”¯å‡º']
    
    total_alerts = 0
    for series_name in test_series:
        print(f"  æª¢æŸ¥ {series_name} è­¦å ±...")
        alerts = analyzer.check_alerts(series_name)
        
        if alerts:
            print(f"    è§¸ç™¼ {len(alerts)} å€‹è­¦å ±:")
            for alert in alerts:
                print(f"      - {alert['alert_name']}: {alert['message']}")
                total_alerts += 1
        else:
            print(f"    æ²’æœ‰è§¸ç™¼è­¦å ±")
    
    conn.close()
    print(f"âœ… è­¦å ±ç³»çµ±æ¸¬è©¦å®Œæˆï¼Œå…±è§¸ç™¼ {total_alerts} å€‹è­¦å ±")
    return True

def test_api_simulation():
    """æ¨¡æ“¬ API å‘¼å«æ¸¬è©¦"""
    print("\nğŸŒ æ¨¡æ“¬ API å‘¼å«æ¸¬è©¦...")
    
    conn = get_test_connection()
    if not conn:
        return False
    
    try:
        cursor = conn.cursor(dictionary=True)
        
        # æ¸¬è©¦ 1: å–å¾—æ™‚é–“åºåˆ—é¡å‹
        print("  æ¸¬è©¦å–å¾—æ™‚é–“åºåˆ—é¡å‹...")
        cursor.execute("""
            SELECT id, name, description, unit, category, data_type, color, icon
            FROM time_series_types
            ORDER BY category, name
        """)
        types = cursor.fetchall()
        print(f"    æ‰¾åˆ° {len(types)} å€‹æ™‚é–“åºåˆ—é¡å‹")
        
        # æ¸¬è©¦ 2: å–å¾—æ™‚é–“åºåˆ—æ•¸æ“š
        print("  æ¸¬è©¦å–å¾—æ™‚é–“åºåˆ—æ•¸æ“š...")
        if types:
            test_type = types[0]['name']
            end_date = date.today()
            start_date = end_date - timedelta(days=30)
            
            cursor.execute("""
                SELECT tsd.*, tst.name as series_name, tst.unit
                FROM time_series_data tsd
                JOIN time_series_types tst ON tsd.series_type_id = tst.id
                WHERE tst.name = %s AND tsd.data_date >= %s AND tsd.data_date <= %s
                ORDER BY tsd.data_date ASC
            """, (test_type, start_date, end_date))
            
            data_points = cursor.fetchall()
            print(f"    {test_type} æœ‰ {len(data_points)} å€‹æ•¸æ“šé»")
        
        # æ¸¬è©¦ 3: å–å¾—è­¦å ±è¨˜éŒ„
        print("  æ¸¬è©¦å–å¾—è­¦å ±è¨˜éŒ„...")
        cursor.execute("""
            SELECT COUNT(*) as count
            FROM time_series_alert_logs
            WHERE triggered_date >= DATE_SUB(CURDATE(), INTERVAL 7 DAY)
        """)
        recent_alerts = cursor.fetchone()['count']
        print(f"    æœ€è¿‘7å¤©æœ‰ {recent_alerts} å€‹è­¦å ±è¨˜éŒ„")
        
        print("âœ… API æ¨¡æ“¬æ¸¬è©¦å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ API æ¨¡æ“¬æ¸¬è©¦å¤±æ•—: {e}")
        return False
    finally:
        conn.close()

def generate_sample_data():
    """ç”¢ç”Ÿç¯„ä¾‹æ•¸æ“šä¾›æ¸¬è©¦"""
    print("\nğŸ² ç”¢ç”Ÿç¯„ä¾‹æ•¸æ“š...")
    
    conn = get_test_connection()
    if not conn:
        return False
    
    analyzer = TimeSeriesAnalyzer(conn)
    
    # ç”¢ç”Ÿéå»30å¤©çš„æ¨¡æ“¬æ•¸æ“š
    base_date = date.today() - timedelta(days=30)
    
    sample_data = [
        # é«”é‡æ•¸æ“š (æ¨¡æ“¬å¾®å¹…è®ŠåŒ–)
        ('é«”é‡', [65.0 + i * 0.1 + (i % 3) * 0.2 for i in range(30)]),
        # æ•¸å­¸æˆç¸¾ (æ¨¡æ“¬å­¸ç¿’é€²æ­¥)
        ('æ•¸å­¸æˆç¸¾', [70 + i * 0.5 + (i % 5) * 3 for i in range(10)]),
        # æœˆæ”¯å‡º (æ¨¡æ“¬æ¯é€±è¨˜éŒ„)
        ('æœˆæ”¯å‡º', [25000 + i * 500 + (i % 2) * 1000 for i in range(8)]),
    ]
    
    total_points = 0
    for series_name, values in sample_data:
        print(f"  ç”¢ç”Ÿ {series_name} æ•¸æ“š...")
        
        for i, value in enumerate(values):
            test_date = base_date + timedelta(days=i)
            if analyzer.store_time_series_data(
                series_name, value, test_date, 
                None, None, 0.95, f"æ¸¬è©¦æ•¸æ“š {i+1}"
            ):
                total_points += 1
    
    conn.close()
    print(f"âœ… æˆåŠŸç”¢ç”Ÿ {total_points} å€‹ç¯„ä¾‹æ•¸æ“šé»")
    return total_points > 0

def run_comprehensive_test():
    """åŸ·è¡Œå®Œæ•´æ¸¬è©¦"""
    print("ğŸš€ é–‹å§‹æ™‚é–“åºåˆ—è¿½è¹¤åŠŸèƒ½å®Œæ•´æ¸¬è©¦")
    print("=" * 60)
    
    test_results = {}
    
    # 1. è¨­å®šè³‡æ–™åº«
    test_results['database_setup'] = setup_test_database()
    
    # 2. ç”¢ç”Ÿç¯„ä¾‹æ•¸æ“š
    test_results['sample_data'] = generate_sample_data()
    
    # 3. æ¸¬è©¦æ•¸æ“šæå–
    test_results['data_extraction'] = test_data_extraction()
    
    # 4. æ¸¬è©¦è¶¨å‹¢åˆ†æ
    test_results['trend_analysis'] = test_trend_analysis()
    
    # 5. æ¸¬è©¦è­¦å ±ç³»çµ±
    test_results['alert_system'] = test_alert_system()
    
    # 6. æ¨¡æ“¬ API æ¸¬è©¦
    test_results['api_simulation'] = test_api_simulation()
    
    # è¼¸å‡ºæ¸¬è©¦çµæœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ¸¬è©¦çµæœæ‘˜è¦:")
    print("-" * 30)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"{test_name.replace('_', ' ').title()}: {status}")
        if result:
            passed += 1
    
    print("-" * 30)
    print(f"ç¸½è¨ˆ: {passed}/{total} é …æ¸¬è©¦é€šé")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦éƒ½é€šéäº†ï¼æ™‚é–“åºåˆ—è¿½è¹¤åŠŸèƒ½å·²å®Œæˆ")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} é …æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦ä¿®å¾©")
        return False

if __name__ == "__main__":
    success = run_comprehensive_test()
    sys.exit(0 if success else 1)
