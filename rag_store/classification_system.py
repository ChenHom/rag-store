#!/usr/bin/env python3
"""
æ–‡ä»¶åˆ†é¡èˆ‡æ¨™è¨˜ç³»çµ±
æä¾›æ™ºèƒ½æ–‡ä»¶åˆ†é¡ã€æ¨™ç±¤ç®¡ç†å’Œå…ƒè³‡æ–™æå–åŠŸèƒ½

ä½¿ç”¨æ–¹å¼ï¼š
python classification_system.py --file /path/to/document.pdf
"""

import os
import re
import json
from datetime import datetime, date
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import mysql.connector
from openai import OpenAI
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

class DocumentClassifier:
    """æ–‡ä»¶åˆ†é¡å™¨"""
    
    def __init__(self):
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.db_config = {
            'host': os.getenv("TIDB_HOST"),
            'user': os.getenv("TIDB_USER"),
            'password': os.getenv("TIDB_PASSWORD"),
            'database': 'rag',
            'ssl_disabled': False,
            'use_unicode': True
        }
    
    def get_db_connection(self):
        """å»ºç«‹è³‡æ–™åº«é€£ç·š"""
        try:
            return mysql.connector.connect(**self.db_config)
        except Exception as e:
            print(f"è³‡æ–™åº«é€£ç·šéŒ¯èª¤: {e}")
            return None
    
    def classify_document(self, text: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ OpenAI API æ™ºèƒ½åˆ†é¡æ–‡ä»¶
        
        Args:
            text: æ–‡ä»¶å…§å®¹æ–‡å­—
            
        Returns:
            Dict: åŒ…å«åˆ†é¡çµæœã€ä¿¡å¿ƒåº¦å’Œæå–è³‡è¨Š
        """
        try:
            prompt = f"""
è«‹åˆ†æä»¥ä¸‹æ–‡ä»¶å…§å®¹ï¼Œä¸¦æä¾›è©³ç´°çš„åˆ†é¡è³‡è¨Šã€‚è«‹ä»¥JSONæ ¼å¼å›ç­”ï¼š

æ–‡ä»¶å…§å®¹ï¼š
{text[:2000]}  # é™åˆ¶è¼¸å…¥é•·åº¦é¿å… token è¶…é™

è«‹æ ¹æ“šä»¥ä¸‹åˆ†é¡æ¨™æº–é€²è¡Œåˆ¤æ–·ï¼š
1. å¸³å–®ï¼šæ°´é›»è²»ã€é›»è©±è²»ã€ä¿¡ç”¨å¡å¸³å–®
2. æ”¶æ“šï¼šè³¼ç‰©æ”¶æ“šã€é†«ç™‚æ”¶æ“šã€æ•™è‚²æ”¯å‡º
3. æˆç¸¾å–®ï¼šå­¸æ ¡æˆç¸¾ã€è€ƒè©¦çµæœã€å­¸ç¿’é€²åº¦
4. å¥åº·è¨˜éŒ„ï¼šèº«é«˜é«”é‡ã€å¥åº·æª¢æŸ¥å ±å‘Šã€ç–«è‹—è¨˜éŒ„
5. ä¿éšªæ–‡ä»¶ï¼šä¿éšªå–®ã€ç†è³ ç”³è«‹ã€ä¿éšªè­‰æ˜
6. ç¨…å‹™æ–‡ä»¶ï¼šå ±ç¨…è³‡æ–™ã€ç¨…å–®ã€æ‰£ç¹³æ†‘å–®
7. åˆç´„æ–‡ä»¶ï¼šç§Ÿç´„ã€è³¼å±‹åˆç´„ã€æœå‹™åˆç´„
8. è­‰æ›¸è­‰ç…§ï¼šç•¢æ¥­è­‰æ›¸ã€å°ˆæ¥­è­‰ç…§ã€è³‡æ ¼è­‰æ˜
9. å…¶ä»–ï¼šæœªåˆ†é¡æˆ–å…¶ä»–é¡å‹æ–‡ä»¶

è«‹æä¾›ä»¥ä¸‹è³‡è¨Šï¼š
{{
    "category": "åˆ†é¡åç¨±",
    "confidence": 0.95,
    "extracted_data": {{
        "amount": 1250.50,
        "date": "2025-01-15",
        "person_name": "ç‹å°æ˜",
        "company": "å°ç£é›»åŠ›å…¬å¸",
        "keywords": ["é›»è²»", "1æœˆä»½", "ä½å®…ç”¨é›»"]
    }},
    "suggested_tags": ["é‡è¦", "å®šæœŸ", "è²¡å‹™"],
    "reasoning": "åˆ¤æ–·ä¾æ“šèªªæ˜"
}}

æ³¨æ„ï¼š
- é‡‘é¡è«‹æå–ä¸»è¦é‡‘é¡ï¼ˆå¦‚ç¸½é‡‘é¡ã€æ‡‰ç¹³é‡‘é¡ï¼‰
- æ—¥æœŸå„ªå…ˆæå–å¸³å–®æ—¥æœŸæˆ–æ–‡ä»¶æ—¥æœŸ
- äººåå˜—è©¦è­˜åˆ¥æ–‡ä»¶æ‰€æœ‰è€…æˆ–ç›¸é—œäººå“¡
- é—œéµå­—æå–3-5å€‹é‡è¦è©å½™
- ä¿¡å¿ƒåº¦ç¯„åœ 0.0-1.0
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ–‡ä»¶åˆ†é¡åŠ©æ‰‹ï¼Œæ“…é•·åˆ†æå®¶åº­æ–‡ä»¶ä¸¦æå–é—œéµè³‡è¨Šã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1  # é™ä½éš¨æ©Ÿæ€§ï¼Œæé«˜åˆ†é¡ä¸€è‡´æ€§
            )
            
            # è§£æ JSON å›æ‡‰
            result_text = response.choices[0].message.content.strip()
            
            # å˜—è©¦æå– JSON å…§å®¹
            json_start = result_text.find('{')
            json_end = result_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_text = result_text[json_start:json_end]
                result = json.loads(json_text)
                return result
            else:
                raise ValueError("ç„¡æ³•è§£æ AI å›æ‡‰ä¸­çš„ JSON")
                
        except Exception as e:
            print(f"æ–‡ä»¶åˆ†é¡éŒ¯èª¤: {e}")
            return {
                "category": "å…¶ä»–",
                "confidence": 0.5,
                "extracted_data": {},
                "suggested_tags": [],
                "reasoning": f"åˆ†é¡å¤±æ•—: {str(e)}"
            }
    
    def extract_amounts(self, text: str) -> List[float]:
        """æå–æ–‡å­—ä¸­çš„é‡‘é¡"""
        # å°ç£å¸¸è¦‹é‡‘é¡æ ¼å¼çš„æ­£å‰‡è¡¨é”å¼
        patterns = [
            r'NT\$?\s*([0-9,]+\.?[0-9]*)',  # NT$ æ ¼å¼
            r'\$\s*([0-9,]+\.?[0-9]*)',      # $ æ ¼å¼
            r'([0-9,]+\.?[0-9]*)\s*å…ƒ',      # å…ƒæ ¼å¼
            r'é‡‘é¡[ï¼š:]\s*([0-9,]+\.?[0-9]*)', # é‡‘é¡: æ ¼å¼
            r'æ‡‰ç¹³[ï¼š:]\s*([0-9,]+\.?[0-9]*)', # æ‡‰ç¹³: æ ¼å¼
            r'ç¸½è¨ˆ[ï¼š:]\s*([0-9,]+\.?[0-9]*)', # ç¸½è¨ˆ: æ ¼å¼
        ]
        
        amounts = []
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '')
                    amount = float(amount_str)
                    amounts.append(amount)
                except ValueError:
                    continue
        
        return sorted(amounts, reverse=True)  # è¿”å›ç”±å¤§åˆ°å°æ’åº
    
    def extract_dates(self, text: str) -> List[str]:
        """æå–æ–‡å­—ä¸­çš„æ—¥æœŸ"""
        patterns = [
            r'(\d{4})[/-](\d{1,2})[/-](\d{1,2})',  # YYYY-MM-DD æˆ– YYYY/MM/DD
            r'(\d{1,2})[/-](\d{1,2})[/-](\d{4})',  # MM/DD/YYYY æˆ– DD/MM/YYYY
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥',     # ä¸­æ–‡æ—¥æœŸæ ¼å¼
            r'æ°‘åœ‹(\d{2,3})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', # æ°‘åœ‹å¹´æ ¼å¼
        ]
        
        dates = []
        for pattern in patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                try:
                    groups = match.groups()
                    if 'æ°‘åœ‹' in pattern:
                        # æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´
                        year = int(groups[0]) + 1911
                        month = int(groups[1])
                        day = int(groups[2])
                    elif pattern.startswith(r'(\d{4})'):
                        # YYYY-MM-DD æ ¼å¼
                        year = int(groups[0])
                        month = int(groups[1])
                        day = int(groups[2])
                    else:
                        # å…¶ä»–æ ¼å¼ï¼Œå‡è¨­ç‚º YYYY-MM-DD
                        if len(groups[2]) == 4:  # å¹´ä»½åœ¨æœ€å¾Œ
                            year = int(groups[2])
                            month = int(groups[0])
                            day = int(groups[1])
                        else:
                            year = int(groups[0])
                            month = int(groups[1])
                            day = int(groups[2])
                    
                    # é©—è­‰æ—¥æœŸæœ‰æ•ˆæ€§
                    date_obj = date(year, month, day)
                    dates.append(date_obj.isoformat())
                except (ValueError, IndexError):
                    continue
        
        return list(set(dates))  # å»é‡è¤‡
    
    def get_category_id(self, category_name: str) -> Optional[int]:
        """æ ¹æ“šåˆ†é¡åç¨±ç²å–åˆ†é¡ ID"""
        conn = self.get_db_connection()
        if not conn:
            return None
            
        try:
            cursor = conn.cursor()
            cursor.execute("SELECT id FROM categories WHERE name = %s", (category_name,))
            result = cursor.fetchone()
            return result[0] if result else None
        except Exception as e:
            print(f"æŸ¥è©¢åˆ†é¡ ID éŒ¯èª¤: {e}")
            return None
        finally:
            conn.close()
    
    def get_or_create_tags(self, tag_names: List[str]) -> List[int]:
        """ç²å–æˆ–å»ºç«‹æ¨™ç±¤ï¼Œè¿”å›æ¨™ç±¤ ID åˆ—è¡¨"""
        conn = self.get_db_connection()
        if not conn:
            return []
            
        tag_ids = []
        try:
            cursor = conn.cursor()
            
            for tag_name in tag_names:
                # æª¢æŸ¥æ¨™ç±¤æ˜¯å¦å­˜åœ¨
                cursor.execute("SELECT id FROM tags WHERE name = %s", (tag_name,))
                result = cursor.fetchone()
                
                if result:
                    tag_ids.append(result[0])
                else:
                    # å»ºç«‹æ–°æ¨™ç±¤
                    cursor.execute(
                        "INSERT INTO tags (name, color, description) VALUES (%s, %s, %s)",
                        (tag_name, '#808080', f'è‡ªå‹•å»ºç«‹çš„æ¨™ç±¤: {tag_name}')
                    )
                    tag_ids.append(cursor.lastrowid)
            
            conn.commit()
            return tag_ids
            
        except Exception as e:
            print(f"è™•ç†æ¨™ç±¤éŒ¯èª¤: {e}")
            conn.rollback()
            return []
        finally:
            conn.close()
    
    def save_document_metadata(self, 
                             filename: str, 
                             file_path: str, 
                             classification_result: Dict[str, Any],
                             ocr_text: str = "",
                             file_size: int = 0,
                             mime_type: str = "") -> Optional[int]:
        """
        å„²å­˜æ–‡ä»¶å…ƒè³‡æ–™åˆ°è³‡æ–™åº«
        
        Returns:
            int: æ–‡ä»¶ IDï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        conn = self.get_db_connection()
        if not conn:
            return None
            
        try:
            cursor = conn.cursor()
            
            # ç²å–åˆ†é¡ ID
            category_id = self.get_category_id(classification_result.get('category', 'å…¶ä»–'))
            
            # æå–è³‡æ–™
            extracted = classification_result.get('extracted_data', {})
            amount = extracted.get('amount')
            extracted_date = extracted.get('date')
            
            # æ’å…¥æ–‡ä»¶è¨˜éŒ„
            insert_sql = """
            INSERT INTO documents (
                filename, original_filename, file_path, file_size, mime_type,
                category_id, document_date, extracted_amount, extracted_date,
                ocr_text, processing_status, confidence_score
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            values = (
                filename,
                filename,
                file_path,
                file_size,
                mime_type,
                category_id,
                extracted_date,
                amount,
                extracted_date,
                ocr_text,
                'completed',
                classification_result.get('confidence', 0.5)
            )
            
            cursor.execute(insert_sql, values)
            document_id = cursor.lastrowid
            
            # è™•ç†æ¨™ç±¤
            suggested_tags = classification_result.get('suggested_tags', [])
            if suggested_tags:
                tag_ids = self.get_or_create_tags(suggested_tags)
                
                # å»ºç«‹æ–‡ä»¶-æ¨™ç±¤é—œè¯
                for tag_id in tag_ids:
                    cursor.execute(
                        "INSERT INTO document_tags (document_id, tag_id) VALUES (%s, %s)",
                        (document_id, tag_id)
                    )
            
            conn.commit()
            print(f"âœ… æ–‡ä»¶å…ƒè³‡æ–™å·²å„²å­˜ï¼Œæ–‡ä»¶ ID: {document_id}")
            return document_id
            
        except Exception as e:
            print(f"å„²å­˜æ–‡ä»¶å…ƒè³‡æ–™éŒ¯èª¤: {e}")
            conn.rollback()
            return None
        finally:
            conn.close()
    
    def get_documents_by_category(self, category_name: str) -> List[Dict[str, Any]]:
        """æ ¹æ“šåˆ†é¡æŸ¥è©¢æ–‡ä»¶"""
        conn = self.get_db_connection()
        if not conn:
            return []
            
        try:
            cursor = conn.cursor(dictionary=True)
            sql = """
            SELECT d.*, c.name as category_name, c.icon, c.color
            FROM documents d
            JOIN categories c ON d.category_id = c.id
            WHERE c.name = %s
            ORDER BY d.created_at DESC
            """
            cursor.execute(sql, (category_name,))
            return cursor.fetchall()
            
        except Exception as e:
            print(f"æŸ¥è©¢æ–‡ä»¶éŒ¯èª¤: {e}")
            return []
        finally:
            conn.close()
    
    def get_documents_by_tags(self, tag_names: List[str]) -> List[Dict[str, Any]]:
        """æ ¹æ“šæ¨™ç±¤æŸ¥è©¢æ–‡ä»¶"""
        conn = self.get_db_connection()
        if not conn:
            return []
            
        try:
            cursor = conn.cursor(dictionary=True)
            placeholders = ','.join(['%s'] * len(tag_names))
            sql = f"""
            SELECT DISTINCT d.*, c.name as category_name
            FROM documents d
            JOIN document_tags dt ON d.id = dt.document_id
            JOIN tags t ON dt.tag_id = t.id
            LEFT JOIN categories c ON d.category_id = c.id
            WHERE t.name IN ({placeholders})
            ORDER BY d.created_at DESC
            """
            cursor.execute(sql, tag_names)
            return cursor.fetchall()
            
        except Exception as e:
            print(f"æ ¹æ“šæ¨™ç±¤æŸ¥è©¢æ–‡ä»¶éŒ¯èª¤: {e}")
            return []
        finally:
            conn.close()
    
    def get_statistics(self) -> Dict[str, Any]:
        """ç²å–åˆ†é¡çµ±è¨ˆè³‡è¨Š"""
        conn = self.get_db_connection()
        if not conn:
            return {}
            
        try:
            cursor = conn.cursor(dictionary=True)
            
            stats = {}
            
            # æŒ‰åˆ†é¡çµ±è¨ˆ
            cursor.execute("""
                SELECT c.name, c.icon, c.color, COUNT(d.id) as count
                FROM categories c
                LEFT JOIN documents d ON c.id = d.category_id
                GROUP BY c.id, c.name, c.icon, c.color
                ORDER BY count DESC
            """)
            stats['by_category'] = cursor.fetchall()
            
            # æŒ‰æ¨™ç±¤çµ±è¨ˆ
            cursor.execute("""
                SELECT t.name, t.color, COUNT(dt.document_id) as count
                FROM tags t
                LEFT JOIN document_tags dt ON t.id = dt.tag_id
                GROUP BY t.id, t.name, t.color
                ORDER BY count DESC
                LIMIT 10
            """)
            stats['by_tags'] = cursor.fetchall()
            
            # ç¸½é«”çµ±è¨ˆ
            cursor.execute("SELECT COUNT(*) as total_documents FROM documents")
            stats['total_documents'] = cursor.fetchone()['total_documents']
            
            cursor.execute("SELECT AVG(confidence_score) as avg_confidence FROM documents")
            result = cursor.fetchone()
            stats['avg_confidence'] = float(result['avg_confidence'] or 0)
            
            return stats
            
        except Exception as e:
            print(f"ç²å–çµ±è¨ˆè³‡è¨ŠéŒ¯èª¤: {e}")
            return {}
        finally:
            conn.close()


def main():
    """æ¸¬è©¦å‡½æ•¸"""
    classifier = DocumentClassifier()
    
    # æ¸¬è©¦æ–‡å­—åˆ†é¡
    test_text = """
    å°ç£é›»åŠ›è‚¡ä»½æœ‰é™å…¬å¸
    é›»è²»é€šçŸ¥å–®
    
    ç”¨æˆ¶åç¨±ï¼šç‹å°æ˜
    åœ°å€ï¼šå°åŒ—å¸‚ä¸­æ­£å€ä¿¡ç¾©è·¯ä¸€æ®µ100è™Ÿ
    é›»è¡¨è™Ÿç¢¼ï¼š12345678
    
    è¨ˆè²»æœŸé–“ï¼š2025å¹´1æœˆ1æ—¥ è‡³ 2025å¹´1æœˆ31æ—¥
    æœ¬æœŸç”¨é›»åº¦æ•¸ï¼š150åº¦
    é›»è²»é‡‘é¡ï¼šNT$ 1,250
    
    æ‡‰ç¹³é‡‘é¡ï¼šNT$ 1,250
    ç¹³è²»æœŸé™ï¼š2025å¹´2æœˆ15æ—¥
    """
    
    print("ğŸ” æ¸¬è©¦æ–‡ä»¶åˆ†é¡...")
    result = classifier.classify_document(test_text)
    print(f"åˆ†é¡çµæœï¼š{json.dumps(result, ensure_ascii=False, indent=2)}")
    
    print("\nğŸ“Š ç²å–çµ±è¨ˆè³‡è¨Š...")
    stats = classifier.get_statistics()
    print(f"çµ±è¨ˆçµæœï¼š{json.dumps(stats, ensure_ascii=False, indent=2)}")


if __name__ == "__main__":
    main()
